{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from FP567_Lib import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# improve/change plot appearance\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We have all the files in resources/market_item_data/, which are item infos in the form of:\n",
    "{ \n",
    "    item_id : \n",
    "    [\n",
    "        [date/time_n+1, price_at_time_n+1, amount_sold_at_time_n+1], [date/time_n+2, price_at_time_n+2, amount_sold_at_time_n+2], ..., [date/time_n+m, price_at_time_n+m, amount_sold_at_time_n+m]\n",
    "    ]\n",
    "}\n",
    "for some amount of time.\n",
    "The amount of time varies between items, as not all items have existed as long as others.\n",
    "\n",
    "Let's make a Market object, which computes a bunch of the info we want.\n",
    "'''\n",
    "market = Market()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "So, lets extend all the items that are not highest_unit_time worth of info, backwards in time,\n",
    "so that the items that do not have as many as highest_unit_time, now have highest_unit_time\n",
    "amount of info, with the time stamp, but just 0, 0 for those days.\n",
    "\n",
    "To do that, we can call the balance method of the Market object, using the \n",
    "longest time span of unix times, and 0, 0 as the default amount sold and price\n",
    "'''\n",
    "market.balance_as_is(0, 0)\n",
    "market.is_balanced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now we have a balanced market and want to include updates into a matrix in the below form.\n",
    "Notice how it is essentially m matrices, where each matrix represents a unit of time,\n",
    "appended onto one another from left to right, and is n rows by k+2 cols = amount_sold col + price col + k embedded update cols\n",
    "        | unix_time_0                                                                                                       | unix_time_1                                                                                                       |     | unix_time_m \n",
    "________| amount_sold_0 | price_0 | update_unix_time_0_feat_1 | update_unix_time_0_feat_2 | ... | update_unix_time_0_feat_k | amount_sold_1 | price_1 | update_unix_time_1_feat_1 | update_unix_time_1_feat_2 | ... | update_unix_time_1_feat_k | ... | amount_sold_m | price_m | update_unix_time_m_feat_1 | update_unix_time_m_feat_2 | ... | update_unix_time_m_feat_k |\n",
    "item_1  |               |         |                           |                           | ... |                           |               |         |                           |                           | ... |                           | ... |               |         |                           |                           | ... |                           |\n",
    "item_2  |               |         |                           |                           | ... |                           |               |         |                           |                           | ... |                           | ... |               |         |                           |                           | ... |                           |\n",
    ".       |       .           .                   .                       .                   ...               .                    .             .                .                            .                ...               .                           .           .                  .                           .                ...               .             | \n",
    ".       |       .           .                   .                       .                   ...               .                    .             .                .                            .                ...               .                           .           .                  .                           .                ...               .             | \n",
    ".       |       .           .                   .                       .                   ...               .                    .             .                .                            .                ...               .                           .           .                  .                           .                ...               .             | \n",
    "item_n  |               |         |                           |                           | ... |                           |               |         |                           |                           | ... |                           |     |               |         |                           |                           | ... |                           |\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Alot of them will be zeros.\n",
    "There will be zeros for\n",
    "    update_unix_time_i_feat_j for all j when there was no update for unix_time_i.\n",
    "    an item's amount_sold_i and price_i when that item was not being sold for unix_time_i.\n",
    "\n",
    "So, need to build a matrix of all the items info and tack on the embedded update.\n",
    "Lets build it so that it goes embedded update cols, amount sold col, price col, so that later,\n",
    "when we do forcasting and a day's worth of cols are forcasted, the price will be the last col\n",
    "of the output and thus, easier to quickly spot the forcasted price.\n",
    "'''\n",
    "market.build_features_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save the features matrix so we dont have to keep making it.\n",
    "'''\n",
    "market.save_market_with_updates_rep_as_csv(PATH_TO_ASSEMBLED_FORCASTING_MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train a forcasting model.\n",
    "'''\n",
    "df, forcasted_day_len = get_forcasting_market_df(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_days = df.shape[1]/forcasted_day_len\n",
    "if not total_days.is_integer() or df.shape[1] % int(total_days) != 0:\n",
    "    raise Exception(\n",
    "        \"The market matrix is malformed. Total days =\",\n",
    "         int(total_days),\n",
    "        \"and forcasted day length =\",\n",
    "        forcasted_day_len,\n",
    "        \"and total cols in the market =\", df.shape[1])\n",
    "\n",
    "num_training_days = int(total_days*0.8)\n",
    "num_validation_days = total_days - num_training_days\n",
    "\n",
    "num_training_cols = num_training_days*forcasted_day_len\n",
    "num_validation_cols = num_validation_days*forcasted_day_len\n",
    "\n",
    "training_days_df = df.loc[:, :num_training_cols]\n",
    "validation_days_df = df.loc[:, num_training_cols:num_validation_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat(tf.convert_to_tensor(df.loc[:, :100], dtype=np.float16), tf.convert_to_tensor(df.loc[:, :100], in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=tf.convert_to_tensor(df.loc[:, :100], dtype=np.float16)\n",
    "t2=tf.convert_to_tensor(df.loc[:, :100], dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stack=tf.stack([t1,t2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find a days at a time to predict value that divides evenly into both the validations\n",
    "and training days (hopefully)\n",
    "'''\n",
    "window_size_to_days_to_predict_scale = 12\n",
    "days_at_a_time_to_predict = 7 # just do 4 if none found\n",
    "for i in range(3, 10):\n",
    "    if i % num_validation_days == i % num_training_days == 0:\n",
    "        days_at_a_time_to_predict = i\n",
    "        break\n",
    "\n",
    "'''\n",
    "Say days_window_size worth of columns are equal to predict_size worth of columns,\n",
    "then slide the window predict_size columns and repeat over and over.\n",
    "'''\n",
    "days_window_size = days_at_a_time_to_predict * window_size_to_days_to_predict_scale * forcasted_day_len\n",
    "predict_size = days_at_a_time_to_predict*forcasted_day_len\n",
    "window_start = 0\n",
    "\n",
    "X_training_tensor_stack = tf.convert_to_tensor(\n",
    "    training_days_df.loc[:, window_start:predict_size], dtype=np.float16)\n",
    "Y_training_tensor_stack = tf.\n",
    "window_start = window_start + predict_size\n",
    "while window_start < training_days_df.shape[1]:\n",
    "    X_training_tensor_stack = tf.stack(\n",
    "        [X_training_tensor_stack, tf.convert_to_tensor(training_days_df.loc[:, window_start:predict_size], dtype=np.float16)],\n",
    "        axis=0)\n",
    "    Y_training_tensor_stack = tf.\n",
    "    window_start = window_start + predict_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('567FP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8737e8cb70a0f7f021fa9834a2ae2129f817e796f624513bd53dcfd8a7bc265"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
