{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from FP567_Lib import *\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# improve/change plot appearance\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "After having their html removed, some of the update files are useless. Lets seperate them\n",
    "'''\n",
    "move_file_to_if_fnx(\n",
    "    PATH_TO_RAW_GAME_UPDATES,\n",
    "    PATH_TO_NOISY_JUNK_UPDATES,\n",
    "    check_if_init_is_game_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "resoureces/raw_updates/\n",
    "    by_year_updates\n",
    "    by_day_updates\n",
    "    game_updates\n",
    "are the same updates, just oranized differently. \n",
    "Let's use the by_year_updates file and make some specfic yy/mm/dd_update files.\n",
    "The by_year_updates have a certain form/pattern.\n",
    "'''\n",
    "unprocd_year_updates = os.path.join(PATH_TO_RAW_UPDATES, \"by_year_updates\")\n",
    "for file in os.listdir(unprocd_year_updates):\n",
    "    print(file[:4])\n",
    "    yy = file[2:4]\n",
    "    lines = open(os.path.join(unprocd_year_updates, file), \"r\").readlines()\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        toks = lines[i].split()\n",
    "        if len(toks) == 2:\n",
    "            maybe_month = toks[1].lower()\n",
    "            if toks[0] == \"##\" and maybe_month in MONTHS:\n",
    "                print(f\"\\t{maybe_month}\")\n",
    "                path_to_month_folder = os.path.join(\n",
    "                    PATH_TO_PROCESSED_UPDATES,\n",
    "                    yy,\n",
    "                    word_month_to_number_month(maybe_month))\n",
    "                os.makedirs(path_to_month_folder, exist_ok=True)\n",
    "                i = i + 2\n",
    "                update_line_toks = lines[i].split()\n",
    "                while len(update_line_toks) > 0:\n",
    "                    d = update_line_toks[1][:-2]\n",
    "                    print(f\"\\t\\t{d}\")\n",
    "                    # write this update as its own file at yy/m/d.\n",
    "                    # if in here, maybe_month is now for sure a month\n",
    "                    with open(os.path.join(path_to_month_folder, f\"{d}.txt\"), 'w') as f:\n",
    "                        f.write(\" \".join(update_line_toks[3:]))\n",
    "\n",
    "                    i = i + 1\n",
    "                    update_line_toks = lines[i].split()\n",
    "        i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Found another common pattern amongst some files with some extractable updates that are different than\n",
    "those that we already got from above notebook cells.\n",
    "The below code parses this pattern, saving the updates.\n",
    "First, to more easily keep track of what I have procd and not, move those that I process over to\n",
    "a \"has_been_processed\" sub folder.\n",
    "'''\n",
    "files_with_pattern = [\n",
    "    \"Combat_Achievements.html.clean\",\n",
    "    \"Achievement_Diary.html.clean\",\n",
    "    \"Polls.html.clean\",\n",
    "    \"Shooting_Stars.html.clean\"]\n",
    "get_updates_from_certain_misc_updates_pattern(files_with_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Another found pattern of updates to extract:\n",
    "## Year\n",
    "\n",
    "day month\n",
    "update\n",
    "'''\n",
    "files_with_pattern = [\"Hidden_updates.html.clean\"]\n",
    "get_updates_from_other_certain_misc_updates_pattern(files_with_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "There is a table-like list of update title and their release dates. Let's include these titles\n",
    "with the updates as they are somewhat informative.\n",
    "'''\n",
    "table = pd.read_table(\n",
    "    os.path.join(PATH_TO_RAW_MISC_UPDATES_BEEN_PROCD, \"postbag_table.txt\"), sep='|')\n",
    "table.columns = list(map(str.strip, table.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[[\"Title\", \"Date\"]].apply(save_table_as_updates, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now, lets take all the organized txt files and combine those that represent the same days,\n",
    "then embedd and save these.\n",
    "'''\n",
    "encoder_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "embedder = hub.load(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year_directory in os.listdir(PATH_TO_PROCESSED_UPDATES_BY_YEAR):\n",
    "    current_year_path = os.path.join(PATH_TO_PROCESSED_UPDATES_BY_YEAR, year_directory)\n",
    "    # print(current_year_path)\n",
    "    for month_directory in os.listdir(current_year_path):\n",
    "        current_month_path = os.path.join(current_year_path, month_directory)\n",
    "        # print(current_month_path)\n",
    "        files = os.listdir(current_month_path)\n",
    "        day_paths = [os.path.join(current_month_path, dd) for dd in files]\n",
    "        dirs = [d_path for d_path in day_paths if '.' not in d_path and os.path.isdir(d_path)]\n",
    "        for day_path in day_paths:\n",
    "            days_embedded = []\n",
    "            # just to make sure these are the .txt files i want\n",
    "            if day_path.endswith(\".txt\"):\n",
    "                try:\n",
    "                    text = open(day_path, 'r').read()\n",
    "                except:\n",
    "                    print(\"Error on \", day_path)\n",
    "                    continue\n",
    "                # check if this file also has a directory\n",
    "                day_dir_path = day_path.split('.')[0]\n",
    "                days_embedded.append(day_dir_path)\n",
    "                # just to make sure these are the directories i want\n",
    "                if day_dir_path in dirs and not day_dir_path.endswith(\".embedding\") and not day_dir_path.endswith(\".txt\"):\n",
    "                    for another_of_same_day_file_txt in os.listdir(day_dir_path):\n",
    "                        if another_of_same_day_file_txt.endswith(\".txt\"):\n",
    "                            text = text + f\" {open(os.path.join(day_dir_path, another_of_same_day_file_txt), 'r').read()}\"\n",
    "                # embed and save this text embedding\n",
    "                np.savetxt(f\"{day_dir_path}.embedded\", embedder([text]), delimiter=',')\n",
    "\n",
    "            # for any days saved strictly as a directory (not up-one-level day.txt + day directory)\n",
    "            for day_dir_path in [d for d in dirs if d not in days_embedded]:\n",
    "                text = \"\"\n",
    "                # just to make sure these are the directories i want\n",
    "                if not day_dir_path.endswith(\".embedding\") and not day_dir_path.endswith(\".txt\"):\n",
    "                    for another_of_same_day_file_txt in os.listdir(day_dir_path):\n",
    "                        if another_of_same_day_file_txt.endswith(\".txt\"):\n",
    "                            text = text + f\" {open(os.path.join(day_dir_path, another_of_same_day_file_txt), 'r').read()}\"\n",
    "                    # embed and save this text embedding\n",
    "                    np.savetxt(f\"{day_dir_path}.embedded\", embedder([text]), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('567FP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8737e8cb70a0f7f021fa9834a2ae2129f817e796f624513bd53dcfd8a7bc265"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
